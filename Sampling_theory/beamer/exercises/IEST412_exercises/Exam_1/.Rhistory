colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
#t estimado
t_est
#varianza estimada de t estimado
v_est_t_est=N^2*(1-(n/N))*(var(c(rep(1,46),rep(0,54)))/n)+(N/n)*sum((1-m_chico/M_grande)*M_grande^2*(var_vector/m_chico))
v_est_t_est
sqrt(v_est_t_est)
#Primero generamos 10 números aleatorios entre 0 y 1
#primero hacemos el ejercicio replicable.
set.seed(123098)
runif(10)
datos=read.csv("exercise0602.csv")
datos
#creamos la frecuencia acumulada
v=cumsum(datos)
v
set.seed(123098)
psi=c(datos$psi)
muestra<-c()
i=1
while (i<=10){
if (runif(1)<=psi[sample(1:length(psi),1)]){
muestra=c(muestra,sample(1:length(psi),1))
i=i+1
}
}
muestra
datos=read.csv("azcounties.csv")
datos
prob=datos$population/sum(datos$population)
prob
#t est
t_est=datos$housing/prob
t_est
#varianza teórica
var_teo=(1/13)*sum(prob*(t_est-sum(datos$population))^2)
var_teo
sqrt(var_teo)
journal
journal
setwd("C:/Users/Eloy/Google Drive/EST/Docencia/2020/IEST 412 - Muestreo II/Ejercicios/Prueba 1")
journal <- read.csv("journal.csv")
journal
journal=journal[journal$numemp!=0,]
#y barra estimado (o proporción estimada)
y_barra=sum(journal$nonprob/journal$numemp)/sum(journal$numemp)
y_barra
#desv. estándar de p estimado
(sum((journal$numemp^2)*(journal$nonprob/journal$numemp-y_barra))/25)*(1/(25*mean(journal$numemp)^2))*(1-(25/1285))
#t estimado
N=580
n=12
M_grande=24
m_chico=3
wij=(N/n)*(M_grande/m_chico)
wij
#acá w_ij es constante debido a que en todos los conglomerados se muestrean la misma cantidad  de tarros de camiones de igual carga
t_est=wij*sum(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
t_est
#v_est
datos=c(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
var_t=var(datos)
var_1=var(c(1,4,0,3,4,0,5,3,7,3,4,0))
var_1
var_2=var(c(5,2,1,6,9,7,5,0,3,1,7,0))
var_2
var_3=var(c(7,4,2,6,8,3,1,2,5,4,9,0))
var_3
v_est=N^2*(1-(n/N))*(var_t/n)+(N/n)*(1-(m_chico/M_grande))*(M_grande^2/m_chico)*(var_1+var_2+var_3)
#Intervalos de confianza
t_inf=t_est-qnorm(0.975)*sqrt(var_t)
t_inf
t_sup=t_est+qnorm(0.975)*sqrt(var_t)
t_sup
#v_est_wr
v_est_wr=N^2*(var_t/n)
v_est_wr
cluster1=c(146, 180, 251, 152, 72, 181, 171, 361, 73, 186)
cluster2=c(99, 101, 52, 121)
cluster3=c(199, 179, 98, 63, 126, 87, 62)
cluster4=c(226, 129, 57, 46, 86, 43, 85, 165)
cluster5=c(12, 23)
cluster6=c(87,43,59)
summary(cluster1)
summary(cluster2)
summary(cluster3)
summary(cluster4)
summary(cluster5)
summary(cluster6)
library("qpcR")
datos=qpcR:::cbind.na(cluster1,cluster2,cluster3,cluster4,cluster5,cluster6)
datos
boxplot(datos)
#pesos
N=45
n=6
M_grande=c(52,19,37,39,8,14)
m_chico=c(10,4,7,8,2,3)
wij=(N/n)*(M_grande/m_chico)
wij
#t estimado
t_est=sum(cluster1*wij[1],cluster2*wij[2],cluster3*wij[3],cluster4*wij[4],cluster5*wij[5],cluster6*wij[6])
t_est
#varianza estimada de t estimado
var_c=c(var(cluster1),var(cluster2),var(cluster3),var(cluster4),var(cluster5),var(cluster6))
v_est=N^2*(1-(n/N))*(var_t/n)+(N/n)*sum((1-m_chico/M_grande)*M_grande^2*(var_c/m_chico))
v_est
sqrt(v_est)
#ventas promedio estimadas por supermercado
y_barra_est=t_est/sum(wij)
y_barra_est
#varianza t barra est
mean_vector=c(mean(cluster1),mean(cluster2),mean(cluster3),mean(cluster4),mean(cluster5),mean(cluster6))
mean_vector
var_total=var(mean_vector)
var_total
var_vector=c(var(cluster1),var(cluster2),var(cluster3),var(cluster4),var(cluster5),var(cluster6))
var_vector
var_y_barra_est=1/mean(M_grande)^2*(1-(n/N))*(var_total/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_y_barra_est
sqrt(var_y_barra_est)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*sum(y_ij))
p_est=t_est/sum(M_grande)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
#t estimado
t_est
#varianza estimada de t estimado
v_est_t_est=N^2*(1-(n/N))*(var(c(rep(1,46),rep(0,54)))/n)+(N/n)*sum((1-m_chico/M_grande)*M_grande^2*(var_vector/m_chico))
v_est_t_est
sqrt(v_est_t_est)
#Primero generamos 10 números aleatorios entre 0 y 1
#primero hacemos el ejercicio replicable.
set.seed(123098)
runif(10)
datos=read.csv("exercise0602.csv")
datos
#creamos la frecuencia acumulada
v=cumsum(datos)
v
set.seed(123098)
psi=c(datos$psi)
muestra<-c()
i=1
while (i<=10){
if (runif(1)<=psi[sample(1:length(psi),1)]){
muestra=c(muestra,sample(1:length(psi),1))
i=i+1
}
}
muestra
datos=read.csv("azcounties.csv")
datos
prob=datos$population/sum(datos$population)
prob
#t est
t_est=datos$housing/prob
t_est
#varianza teórica
var_teo=(1/13)*sum(prob*(t_est-sum(datos$population))^2)
var_teo
sqrt(var_teo)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(M_grande)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(M_grande)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(M_grande)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
p_est
sum(M_grande)
wij
sum(wij)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(M_grande)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
p_est
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(wij)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
p_est
setwd("C:/Users/Eloy/Google Drive/Teaching/topics/Sampling_theory/beamer/exercises/IEST412_exercises/Exam_1")
setwd("C:/Users/Eloy/Google Drive/Teaching/topics/Sampling_theory/beamer/exercises/IEST412_exercises/Exam_1")
journal <- read.csv("journal.csv")
journal
journal=journal[journal$numemp!=0,]
#y barra estimado (o proporción estimada)
y_barra=sum(journal$nonprob/journal$numemp)/26
y_barra
#desv. estándar de p estimado
(sum((journal$numemp^2)*(journal$nonprob/journal$numemp-y_barra))/25)*(1/(25*mean(journal$numemp)^2))*(1-(25/1285))
#t estimado
N=580
n=12
M_grande=24
m_chico=3
wij=(N/n)*(M_grande/m_chico)
wij
#acá w_ij es constante debido a que en todos los conglomerados se muestrean la misma cantidad  de tarros de camiones de igual carga
t_est=wij*sum(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
t_est
#v_est
datos=c(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
var_t=var(datos)
var_1=var(c(1,4,0,3,4,0,5,3,7,3,4,0))
var_1
var_2=var(c(5,2,1,6,9,7,5,0,3,1,7,0))
var_2
var_3=var(c(7,4,2,6,8,3,1,2,5,4,9,0))
var_3
v_est=N^2*(1-(n/N))*(var_t/n)+(N/n)*(1-(m_chico/M_grande))*(M_grande^2/m_chico)*(var_1+var_2+var_3)
v_est
#Intervalos de confianza
t_inf=t_est-qnorm(0.975)*sqrt(var_t)
t_inf
t_sup=t_est+qnorm(0.975)*sqrt(var_t)
t_sup
#v_est_wr
v_est_wr=N^2*(var_t/n)
v_est_wr
cluster1=c(146, 180, 251, 152, 72, 181, 171, 361, 73, 186)
cluster2=c(99, 101, 52, 121)
cluster3=c(199, 179, 98, 63, 126, 87, 62)
cluster4=c(226, 129, 57, 46, 86, 43, 85, 165)
cluster5=c(12, 23)
cluster6=c(87,43,59)
summary(cluster1)
summary(cluster2)
summary(cluster3)
summary(cluster4)
summary(cluster5)
summary(cluster6)
library("qpcR")
install.packages("robustbase")
setwd("C:/Users/Eloy/Google Drive/Teaching/topics/Sampling_theory/beamer/exercises/IEST412_exercises/Exam_1")
journal <- read.csv("journal.csv")
journal
journal=journal[journal$numemp!=0,]
#y barra estimado (o proporción estimada)
y_barra=sum(journal$nonprob/journal$numemp)/26
y_barra
#desv. estándar de p estimado
(sum((journal$numemp^2)*(journal$nonprob/journal$numemp-y_barra))/25)*(1/(25*mean(journal$numemp)^2))*(1-(25/1285))
#t estimado
N=580
n=12
M_grande=24
m_chico=3
wij=(N/n)*(M_grande/m_chico)
wij
#acá w_ij es constante debido a que en todos los conglomerados se muestrean la misma cantidad  de tarros de camiones de igual carga
t_est=wij*sum(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
t_est
#v_est
datos=c(1,4,0,3,4,0,5,3,7,3,4,0,5,2,1,6,9,7,5,0,3,1,7,0,7,4,2,6,8,3,1,2,5,4,9,0)
var_t=var(datos)
var_1=var(c(1,4,0,3,4,0,5,3,7,3,4,0))
var_1
var_2=var(c(5,2,1,6,9,7,5,0,3,1,7,0))
var_2
var_3=var(c(7,4,2,6,8,3,1,2,5,4,9,0))
var_3
v_est=N^2*(1-(n/N))*(var_t/n)+(N/n)*(1-(m_chico/M_grande))*(M_grande^2/m_chico)*(var_1+var_2+var_3)
v_est
#Intervalos de confianza
t_inf=t_est-qnorm(0.975)*sqrt(var_t)
t_inf
t_sup=t_est+qnorm(0.975)*sqrt(var_t)
t_sup
#v_est_wr
v_est_wr=N^2*(var_t/n)
v_est_wr
cluster1=c(146, 180, 251, 152, 72, 181, 171, 361, 73, 186)
cluster2=c(99, 101, 52, 121)
cluster3=c(199, 179, 98, 63, 126, 87, 62)
cluster4=c(226, 129, 57, 46, 86, 43, 85, 165)
cluster5=c(12, 23)
cluster6=c(87,43,59)
summary(cluster1)
summary(cluster2)
summary(cluster3)
summary(cluster4)
summary(cluster5)
summary(cluster6)
library("qpcR")
datos=qpcR:::cbind.na(cluster1,cluster2,cluster3,cluster4,cluster5,cluster6)
datos
boxplot(datos)
#pesos
N=45
n=6
M_grande=c(52,19,37,39,8,14)
m_chico=c(10,4,7,8,2,3)
wij=(N/n)*(M_grande/m_chico)
wij
#t estimado
t_est=sum(cluster1*wij[1],cluster2*wij[2],cluster3*wij[3],cluster4*wij[4],cluster5*wij[5],cluster6*wij[6])
t_est
#varianza estimada de t estimado
var_t=var(c(cluster1,cluster2,cluster3,cluster4,cluster5,cluster6))
var_t
var_c=c(var(cluster1),var(cluster2),var(cluster3),var(cluster4),var(cluster5),var(cluster6))
v_est=N^2*(1-(n/N))*(var_t/n)+(N/n)*sum((1-m_chico/M_grande)*M_grande^2*(var_c/m_chico))
v_est
sqrt(v_est)
#ventas promedio estimadas por supermercado
y_barra_est=t_est/sum(wij*m_chico)
y_barra_est
#varianza t barra est
mean_vector=c(mean(cluster1),mean(cluster2),mean(cluster3),mean(cluster4),mean(cluster5),mean(cluster6))
mean_vector
var_total=var(mean_vector)
var_total
var_vector=c(var(cluster1),var(cluster2),var(cluster3),var(cluster4),var(cluster5),var(cluster6))
var_vector
var_y_barra_est=1/mean(M_grande)^2*(1-(n/N))*(var_total/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_y_barra_est
sqrt(var_y_barra_est)
#pesos
N=29
n=4
M_grande=c(792,447,511,800)
m_chico=c(25,15,20,40)
wij=(N/n)*(M_grande/m_chico)
wij
#p estimado
smokers=c(10,3,6,27)
y_ij=smokers/m_chico
y_ij
t_est=sum(wij*y_ij)
p_est=t_est/sum(wij)
p_est
#var p estimado
colegio1=c(rep(1,10),rep(0,15))
colegio2=c(rep(1,3),rep(0,12))
colegio3=c(rep(1,6),rep(0,14))
colegio4=c(rep(1,27),rep(0,13))
var_vector=c(var(colegio1),var(colegio2),var(colegio3),var(colegio4))
var_vector
var_p_est=1/mean(M_grande)^2*(1-(n/N))*(var(y_ij)/n)+(1/(n*N*mean(M_grande)^2))*sum(M_grande^2*(1-(m_chico/M_grande))*(var_vector^2/m_chico))
var_p_est
sqrt(var_p_est)
#t estimado
t_est
#varianza estimada de t estimado
v_est_t_est=N^2*(1-(n/N))*(var(c(rep(1,46),rep(0,54)))/n)+(N/n)*sum((1-m_chico/M_grande)*M_grande^2*(var_vector/m_chico))
v_est_t_est
sqrt(v_est_t_est)
#Primero generamos 10 números aleatorios entre 0 y 1
#primero hacemos el ejercicio replicable.
set.seed(123098)
runif(10)
datos=read.csv("exercise0602.csv")
datos
#creamos la frecuencia acumulada
v=cumsum(datos)
v
set.seed(123098)
psi=c(datos$psi)
muestra<-c()
i=1
while (i<=10){
if (runif(1)<=psi[sample(1:length(psi),1)]){
muestra=c(muestra,sample(1:length(psi),1))
i=i+1
}
}
muestra
datos=read.csv("azcounties.csv")
datos
prob=datos$population/sum(datos$population)
prob
#t est
t_est=datos$housing/prob
t_est
#varianza teórica
var_teo=(1/13)*sum(prob*(t_est-sum(datos$population))^2)
var_teo
sqrt(var_teo)
version
