\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage{mathtools}
% https://github.com/rstudio/rmarkdown/issues/337
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

% https://github.com/rstudio/rmarkdown/pull/252
\usepackage{titling}
\setlength{\droptitle}{-2em}

\pretitle{\vspace{\droptitle}\centering\huge}
\posttitle{\par}

\preauthor{\centering\large\emph}
\postauthor{\par}

\predate{\centering\large\emph}
\postdate{\par}

\date{}

\begin{document}

\subsection{Ejercicios Prueba 1 - IEST
412}\label{ejercicios-prueba-1---iest-412}

\subsubsection{Muestreo por
conglomerado}\label{muestreo-por-conglomerado}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A city council of a small city wants to know the proportion of
  eligible voters that oppose having a incinerator of Phoenix garbage
  opened just outside of the city limits. They randomly select 100
  residential numbers from the city's telephone book that contains 3,000
  such numbers. Each selected residence is then called and asked for (a)
  the total number of eligible voters and (b) the number of voters
  opposed to the incinerator. A total of 157 voters were surveyed; of
  these, 23 refused to answer the question. Of the remaining 134 voters,
  112 opposed the incinerator, so the council estimates the proportion
  by: \[\hat{p}=112/134=0.83582\] with,
  \[\hat{V}(\hat{p})=0.83582(1-0.83582)/134=0.00102\] ¿Son válidos estas
  estimaciones? ¿Por qué?
\end{enumerate}

Acá hay dos problemas con las estimaciones: la primera -más a la vista-
es la no incorporación de los votantes que no desearon responder en la
estimación, y segundo: las estimaciones a las que se llegaron fueron
utilizando un M.A.S.,(y no un M.C), de el curso anterior nosotros
sabemos que (bajo un M.A.S.), se tiene:
\[\hat{p}=\dfrac{1}{n}\sum_{i=1}^{n}y_i=\overline{y}\] al binarizar los
valores \(y_i\) como es este caso, y

\[\mathbb{V}(\hat{p})=\left(\dfrac{N-n}{N-1}\right)\dfrac{p(1-p)}{n}\] ,

\[\widehat{\mathbb{V}(\hat{p})}=\left(\dfrac{N-n}{N}\right)\dfrac{\hat{p}(1-\hat{p})}{n-1}\]
En donde claramente, no se utilizó un factor de corrección y se asumió
el \(p\) obtenido como poblacional. Así, estas estimaciones no son
válidas.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Senturia et al. (1994) describe a survey taken to study how many
  children have access to guns in their households. Questionnaires were
  distributed to all parents who attended selected clinics in the
  Chicago area during a one-week period for well or sick child visits.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Suppose that the quantity of interest is percentage of the households
  with guns. Describe why this is a cluster sample. What is the psu? The
  ssu? Is it a one-stage or two-stage cluster sample? How would you
  estimate the percentage of households with guns, and the standard
  error of your estimate?
\end{itemize}

Claramente, el muestreo descrito es un muestreo por conglomerado, pues
los cuestionarios son dirigidos a los hogares y estos los podemos
considerar un conglomerado con todas sus propiedades que esto conlleva.
Las \(\textbf{UPM}\) son los hogares, y las \(\textbf{USM}\) es la
presencia o no de armas dentro del hogar. El muestreo es unietápico.
Como mencioné anteriormente, y según lo visto en el curso de Muestreo I,
para pasar de media a proporción (y en consecuencia sus estimaciones
también) basta sólo binarizar lo observado, esto es -dentro de este
contexto- tener los datos de presencia o ausencia de armas dentro del
hogar, luego resta sólo utilizar las fórmulas vistas para M.C.
unietápico.

\begin{itemize}
\tightlist
\item
  What is the sampling population for this study? Do you think this
  sampling procedure results in a representative sample of households
  with children? Why, or why not?
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Kleppel et al. (2004) report on a study of wetlands in upstate
  NewYork. Four wetlands were selected for the study: Two of the
  wetlands drain watersheds from small towns and the other two drain
  suburban watersheds. Quantities such as pH were measured at two to
  four randomly selected sites within each of the four wetlands.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Describe why this is a cluster sample. What are the psus? The ssus?
  How would you estimate the average pH in the suburban wetlands?
\end{itemize}

Es un M.C. debido a que los humedales (al igual que los hogares) son
similares entre sí. (a diferencia de los estratos). Las \(\textbf{UPM}\)
son los humadales y las \(\text{USM}\) son los sitios dentro de los
humedales.

\begin{itemize}
\tightlist
\item
  The authors used Student's two-sample t test to compare the average pH
  from the sites in the suburban wetlands with the average pH from the
  sites in the small town wetlands, treating all sites as independent.
  Is this analysis appropriate? Why, or why not?
\end{itemize}

Recordar que este test tiene 3 supuestos: normalidad de los promedios,
homocedasticidad e independencia de los datos. En este caso, la
normalidad puede ser cuestionada, pues el rango del ph es \([0,14]\)
siendo \(0\) lo más ácido y \(14\) lo más básico, claramente fallando en
el rango normal. Homocedasticidad puede ser omitida, pues este test
bastante robusto en cuanto a varianzas desiguales. Y la independencia
pareciera que no se cumple, pues sospecharía que los humedales han de
interactuar de alguna manera pues son humedales de la misma
localización.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Survey evidence is often introduced in court cases involving trademark
  violation and employment discrimination. There has been controversy,
  however, about whether nonprobability samples are acceptable as
  evidence in litigation. Jacoby and Handlin (1991) selected 26 from a
  list of 1285 scholarly journals in the social and behavioral sciences.
  They examined all articles published during 1988 for the selected
  journals, and recorded (1) the number of articles in the journal that
  described empirical research from a survey (they excluded articles in
  which the authors analyzed survey data which had been collected by
  someone else) and (2) the total number of articles for each journal
  which used probability sampling, nonprobability sampling, or for which
  the sampling method could not be determined. The data are in file
  journal.dat.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Explain why this is a cluster sample.
\item
  Estimate the proportion of articles in the 1285 journals that use
  nonprobability sampling, and give the standard error of your estimate.
\item
  The authors conclude that, because ``an overwhelming proportion of . .
  . recognized scholarly and practitioner experts rely on
  non-probability sampling designs,''courts ``should have no problem
  admitting otherwise well-conducted non-probability surveys and
  according them due weight'' (p.~175). Comment on this statement.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{journal}
\end{Highlighting}
\end{Shaded}

La explicación de porqué es un M.C. es clara, pues las revistas son
consideradas como conglomerados (y tiene sus propiedades). La estimación
de la proporción de artículos en las 1285 revistas que usan muestreos no
probabilísticos, están dados por las fórmulas:

\[\hat{t}_{unb}=\dfrac{N}{n}\sum_{i\in S} t_i\]

número total de \(\textbf{USM}\) en la población

\[M_0=\sum_{i=1}^{N} M_i\]

entonces

\[\widehat{\overline{y}_{unb}}=\widehat{t}_{unb}/M_0\] y donde su
desviación estándar está dada por:

\begin{align*}
SE[\widehat{\overline{y}_r}]&=\sqrt{ \left(1-\dfrac{n}{N}\right)\dfrac{1}{n\overline{M}^2}\dfrac{\sum_{i\in \mathcal{S} (t_i-\widehat{\overline{y}_r}M_i)^2}}{n-1}}\\
&=\sqrt{ \left(1-\dfrac{n}{N}\right)\dfrac{1}{n\overline{M}^2}\dfrac{\sum_{i\in \mathcal{S}} M_{i}^{2}(\overline{y}_i-\widehat{\overline{y}_r})^2}{n-1}}
\end{align*}

así, podemos podemos calcular lo pedido como:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{journal=journal[journal}\OperatorTok{$}\NormalTok{numemp}\OperatorTok{!=}\DecValTok{0}\NormalTok{,]}
\CommentTok{#y barra estimado (o proporción estimada)}
\NormalTok{y_barra=}\KeywordTok{sum}\NormalTok{(journal}\OperatorTok{$}\NormalTok{nonprob}\OperatorTok{/}\NormalTok{journal}\OperatorTok{$}\NormalTok{numemp)}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(journal}\OperatorTok{$}\NormalTok{numemp)}
\NormalTok{y_barra}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09582191
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#desv. estándar de p estimado}
\NormalTok{(}\KeywordTok{sum}\NormalTok{((journal}\OperatorTok{$}\NormalTok{numemp}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\NormalTok{(journal}\OperatorTok{$}\NormalTok{nonprob}\OperatorTok{/}\NormalTok{journal}\OperatorTok{$}\NormalTok{numemp}\OperatorTok{-}\NormalTok{y_barra))}\OperatorTok{/}\DecValTok{25}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{25}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(journal}\OperatorTok{$}\NormalTok{numemp)}\OperatorTok{^}\DecValTok{2}\NormalTok{))}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(}\DecValTok{25}\OperatorTok{/}\DecValTok{1285}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.05594624
\end{verbatim}

¿Según estos resultados, que podemos concluir?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  A language school owner takes an SRS of 10 of the 72 Introductory
  Spanish classes offered by the school. Each student in each of the
  sampled classes is given a vocabulary test and is also asked whether
  he or she is planning a trip to a Spanish-speaking country in the next
  year. The data are in file spanish.dat.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Estimate the total number of students planning a trip to a
  Spanish-speaking country in the next year, and give a 95\% CI.
\item
  Estimate the mean vocabulary test score for Introductory Spanish
  students in the language school, and give a 95\% CI.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  An inspector samples cans from a truckload of canned creamed corn to
  estimate the total number of worm fragments in the truckload. The
  truck has 580 cases; each case contains 24 cans. The inspector samples
  12 cases at random, and subsamples 3 cans randomly from each selected
  case.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{C:/Users/Eloy/Google\%20Drive/EST/Docencia/2020/IEST\%20412\%20-\%20Muestreo\%20II/Ejercicios/Prueba\%201/problema6.jpg}
\caption{}
\end{figure}

\begin{itemize}
\tightlist
\item
  Debemos usar
  \[\hat{t}_{unb}=\sum_{i\in \mathcal{S}}\sum_{j\in \mathcal{S}_i} w_{ij}y_{ij}\]
  en donde, \[w_{ij}=\dfrac{NM_i}{n m_i}\] y
  \[\widehat{\mathbb{V}[ \hat{t}_{unb} ]}=N^2 \left( 1- \dfrac{n}{N}\right) \dfrac{s_{t}^{2}}{n}+\dfrac{N}{n}\sum_{i\in \mathcal{S}} \left( 1 -\dfrac{m_i}{M_i}\right)M_{i}^{2} \dfrac{s_{i}^{2}}{m_i} \]
  que debemos compararlo con:
\end{itemize}

\[\widehat{\mathbb{V}_{WR}[ \hat{t}_{unb} ]}=N^2 \dfrac{s_{t}^2}{n}\]
Así,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#t estimado}
\NormalTok{N=}\DecValTok{580}
\NormalTok{n=}\DecValTok{12}
\NormalTok{M_grande=}\DecValTok{24}
\NormalTok{m_chico=}\DecValTok{3}
\NormalTok{wij=(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\NormalTok{(M_grande}\OperatorTok{/}\NormalTok{m_chico)}
\NormalTok{wij}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 386.6667
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#acá w_ij es constante debido a que en todos los conglomerados se muestrean la misma cantidad  de tarros de camiones de igual carga}
\NormalTok{t_est=wij}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{t_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50653.33
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#v_est}
\NormalTok{datos=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{var_t=}\KeywordTok{var}\NormalTok{(datos)}
\NormalTok{var_}\DecValTok{1}\NormalTok{=}\KeywordTok{var}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\NormalTok{var_}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.878788
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_}\DecValTok{2}\NormalTok{=}\KeywordTok{var}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\NormalTok{var_}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.424242
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_}\DecValTok{3}\NormalTok{=}\KeywordTok{var}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\NormalTok{var_}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.022727
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v_est=N}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(n}\OperatorTok{/}\NormalTok{N))}\OperatorTok{*}\NormalTok{(var_t}\OperatorTok{/}\NormalTok{n)}\OperatorTok{+}\NormalTok{(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(m_chico}\OperatorTok{/}\NormalTok{M_grande))}\OperatorTok{*}\NormalTok{(M_grande}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{m_chico)}\OperatorTok{*}\NormalTok{(var_}\DecValTok{1}\OperatorTok{+}\NormalTok{var_}\DecValTok{2}\OperatorTok{+}\NormalTok{var_}\DecValTok{3}\NormalTok{)}
\CommentTok{#Intervalos de confianza}
\NormalTok{t_inf=t_est}\OperatorTok{-}\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(var_t)}
\NormalTok{t_inf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50648.01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t_sup=t_est}\OperatorTok{+}\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(var_t)}
\NormalTok{t_sup}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50658.66
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#v_est_wr}
\NormalTok{v_est_wr=N}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(var_t}\OperatorTok{/}\NormalTok{n)}
\NormalTok{v_est_wr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 206890.4
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  The new candy Green Globules is being test-marketed in an area of
  upstate NewYork. The market research firm decided to sample 6 cities
  from the 45 cities in the area and then to sample supermarkets within
  cities, wanting to know the number of cases of Green Globules sold.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{C:/Users/Eloy/Google\%20Drive/EST/Docencia/2020/IEST\%20412\%20-\%20Muestreo\%20II/Ejercicios/Prueba\%201/problema7.jpg}
\caption{}
\end{figure}

\begin{itemize}
\tightlist
\item
  Obtain summary statistics for each cluster. Plot the data, and
  estimate the total number of cases sold, and the average number sold
  per supermarket, along with the standard errors of your estimates.
\end{itemize}

El análisis exploratorio de datos es estándar:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster1=}\KeywordTok{c}\NormalTok{(}\DecValTok{146}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{251}\NormalTok{, }\DecValTok{152}\NormalTok{, }\DecValTok{72}\NormalTok{, }\DecValTok{181}\NormalTok{, }\DecValTok{171}\NormalTok{, }\DecValTok{361}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{186}\NormalTok{)}
\NormalTok{cluster2=}\KeywordTok{c}\NormalTok{(}\DecValTok{99}\NormalTok{, }\DecValTok{101}\NormalTok{, }\DecValTok{52}\NormalTok{, }\DecValTok{121}\NormalTok{)}
\NormalTok{cluster3=}\KeywordTok{c}\NormalTok{(}\DecValTok{199}\NormalTok{, }\DecValTok{179}\NormalTok{, }\DecValTok{98}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{126}\NormalTok{, }\DecValTok{87}\NormalTok{, }\DecValTok{62}\NormalTok{)}
\NormalTok{cluster4=}\KeywordTok{c}\NormalTok{(}\DecValTok{226}\NormalTok{, }\DecValTok{129}\NormalTok{, }\DecValTok{57}\NormalTok{, }\DecValTok{46}\NormalTok{, }\DecValTok{86}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{85}\NormalTok{, }\DecValTok{165}\NormalTok{)}
\NormalTok{cluster5=}\KeywordTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{23}\NormalTok{)}
\NormalTok{cluster6=}\KeywordTok{c}\NormalTok{(}\DecValTok{87}\NormalTok{,}\DecValTok{43}\NormalTok{,}\DecValTok{59}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(cluster1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    72.0   147.5   175.5   177.3   184.8   361.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cluster2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   52.00   87.25  100.00   93.25  106.00  121.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cluster3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    62.0    75.0    98.0   116.3   152.5   199.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cluster4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   43.00   54.25   85.50  104.62  138.00  226.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cluster5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12.00   14.75   17.50   17.50   20.25   23.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(cluster6)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##      43      51      59      63      73      87
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"qpcR"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: MASS
\end{verbatim}

\begin{verbatim}
## Loading required package: minpack.lm
\end{verbatim}

\begin{verbatim}
## Loading required package: rgl
\end{verbatim}

\begin{verbatim}
## Loading required package: robustbase
\end{verbatim}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{datos=qpcR}\OperatorTok{:::}\KeywordTok{cbind.na}\NormalTok{(cluster1,cluster2,cluster3,cluster4,cluster5,cluster6)}
\NormalTok{datos}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       cluster1 cluster2 cluster3 cluster4 cluster5 cluster6
##  [1,]      146       99      199      226       12       87
##  [2,]      180      101      179      129       23       43
##  [3,]      251       52       98       57       NA       59
##  [4,]      152      121       63       46       NA       NA
##  [5,]       72       NA      126       86       NA       NA
##  [6,]      181       NA       87       43       NA       NA
##  [7,]      171       NA       62       85       NA       NA
##  [8,]      361       NA       NA      165       NA       NA
##  [9,]       73       NA       NA       NA       NA       NA
## [10,]      186       NA       NA       NA       NA       NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(datos)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ej_p1_files/figure-latex/unnamed-chunk-5-1.pdf} Luego,
para la estimación del número total de casos, utilizamos la misma
fórmula que en el problema 6. Así,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#pesos}
\NormalTok{N=}\DecValTok{45}
\NormalTok{n=}\DecValTok{6}
\NormalTok{M_grande=}\KeywordTok{c}\NormalTok{(}\DecValTok{52}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{37}\NormalTok{,}\DecValTok{39}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{14}\NormalTok{)}
\NormalTok{m_chico=}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{wij=(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\NormalTok{(M_grande}\OperatorTok{/}\NormalTok{m_chico)}
\NormalTok{wij}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 39.00000 35.62500 39.64286 36.56250 30.00000 35.00000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#t estimado}
\NormalTok{t_est=}\KeywordTok{sum}\NormalTok{(cluster1}\OperatorTok{*}\NormalTok{wij[}\DecValTok{1}\NormalTok{],cluster2}\OperatorTok{*}\NormalTok{wij[}\DecValTok{2}\NormalTok{],cluster3}\OperatorTok{*}\NormalTok{wij[}\DecValTok{3}\NormalTok{],cluster4}\OperatorTok{*}\NormalTok{wij[}\DecValTok{4}\NormalTok{],cluster5}\OperatorTok{*}\NormalTok{wij[}\DecValTok{5}\NormalTok{],cluster6}\OperatorTok{*}\NormalTok{wij[}\DecValTok{6}\NormalTok{])}
\NormalTok{t_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 152972.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#varianza estimada de t estimado}
\NormalTok{var_c=}\KeywordTok{c}\NormalTok{(}\KeywordTok{var}\NormalTok{(cluster1),}\KeywordTok{var}\NormalTok{(cluster2),}\KeywordTok{var}\NormalTok{(cluster3),}\KeywordTok{var}\NormalTok{(cluster4),}\KeywordTok{var}\NormalTok{(cluster5),}\KeywordTok{var}\NormalTok{(cluster6))}
\NormalTok{v_est=N}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(n}\OperatorTok{/}\NormalTok{N))}\OperatorTok{*}\NormalTok{(var_t}\OperatorTok{/}\NormalTok{n)}\OperatorTok{+}\NormalTok{(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\KeywordTok{sum}\NormalTok{((}\DecValTok{1}\OperatorTok{-}\NormalTok{m_chico}\OperatorTok{/}\NormalTok{M_grande)}\OperatorTok{*}\NormalTok{M_grande}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(var_c}\OperatorTok{/}\NormalTok{m_chico))}
\NormalTok{v_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 20375293
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(v_est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4513.9
\end{verbatim}

Para estimar el número medio de unidades vendidas usamos:

\[\widehat{\overline{y}_r}=\dfrac{\widehat{t}_{unb}}{\widehat{M}_0}= \dfrac{ \sum_{i\in \mathcal{S}} \sum_{i\in \mathcal{S}_j} w_{ij}y_{ij}}{\sum_{i\in \mathcal{S}} \sum_{i\in \mathcal{S}_j} w_{ij}}\]

en donde su varianza está dada por:
\[\widehat{\mathbb{V}[ \hat{\overline{y}}_{r} ]}=\dfrac{1}{\overline{M}^2}\left( 1- \dfrac{n}{N}\right) \dfrac{s_{r}^{2}}{n}+\dfrac{1}{nN\overline{M}^2}\sum_{i\in \mathcal{S}} M_{i}^2 \left( 1 -\dfrac{m_i}{M_i}\right)\dfrac{s_{i}^{2}}{m_i} \]
Así,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#ventas promedio estimadas por supermercado}
\NormalTok{y_barra_est=t_est}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(wij)}
\NormalTok{y_barra_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 708.7614
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#varianza t barra est}
\NormalTok{mean_vector=}\KeywordTok{c}\NormalTok{(}\KeywordTok{mean}\NormalTok{(cluster1),}\KeywordTok{mean}\NormalTok{(cluster2),}\KeywordTok{mean}\NormalTok{(cluster3),}\KeywordTok{mean}\NormalTok{(cluster4),}\KeywordTok{mean}\NormalTok{(cluster5),}\KeywordTok{mean}\NormalTok{(cluster6))}
\NormalTok{mean_vector}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 177.3000  93.2500 116.2857 104.6250  17.5000  63.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_total=}\KeywordTok{var}\NormalTok{(mean_vector)}
\NormalTok{var_total}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2870.337
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_vector=}\KeywordTok{c}\NormalTok{(}\KeywordTok{var}\NormalTok{(cluster1),}\KeywordTok{var}\NormalTok{(cluster2),}\KeywordTok{var}\NormalTok{(cluster3),}\KeywordTok{var}\NormalTok{(cluster4),}\KeywordTok{var}\NormalTok{(cluster5),}\KeywordTok{var}\NormalTok{(cluster6))}
\NormalTok{var_vector}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6988.9000  854.9167 2974.5714 4172.2679   60.5000  496.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_y_barra_est=}\DecValTok{1}\OperatorTok{/}\KeywordTok{mean}\NormalTok{(M_grande)}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(n}\OperatorTok{/}\NormalTok{N))}\OperatorTok{*}\NormalTok{(var_total}\OperatorTok{/}\NormalTok{n)}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(n}\OperatorTok{*}\NormalTok{N}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(M_grande)}\OperatorTok{^}\DecValTok{2}\NormalTok{))}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(M_grande}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(m_chico}\OperatorTok{/}\NormalTok{M_grande))}\OperatorTok{*}\NormalTok{(var_vector}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{m_chico))}
\NormalTok{var_y_barra_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 68935.03
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(var_y_barra_est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 262.5548
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{13}
\tightlist
\item
  A researcher took an SRS of 4 high schools from a region with 29 high
  schools for a study on the prevalence of smoking among female high
  school students in the region. The results were as follows:
\end{enumerate}

\begin{figure}
\centering
\includegraphics{C:/Users/Eloy/Google\%20Drive/EST/Docencia/2020/IEST\%20412\%20-\%20Muestreo\%20II/Ejercicios/Prueba\%201/problema14.jpg}
\caption{}
\end{figure}

\begin{itemize}
\tightlist
\item
  Estimate the percentage of female high school students in the region
  who smoke, along with a 95\% CI.
\item
  Estimate the total number of female high school students in the region
  who smoke, along with a 95\% CI.
\item
  The researcher now wants to study the prevalence of smoking and other
  risk behaviors among female high school students in a different region
  with 35 high schools. She intends to drive to n of the schools and
  then interview some or all of the female students in the selected
  schools. Assuming that MSB and MSW are similar in the two regions, use
  information from the study of 4 schools to estimate R2 a and design a
  cluster sample for the new study. Suppose it takes about 50 hours per
  school to contact school officials, obtain permission, obtain a list
  of female students, and travel back and forth. Although interviews
  themselves are only about 10 minutes, it takes about 30 minutes per
  interview obtained to allow for additional scheduling of no-shows,
  obtaining parental permission, and other administrative tasks. The
  investigator would like to spend 300 hours or less on the data
  collection.
\end{itemize}

Para la estimación de los porcentaje, utilizamos las fórmulas para la
media problacional. Notamos que el caso descrito es un muestreo por
conglomerado bietápico. Obtendremos las estimaciones puntuales y las
varianzas, los intervalos se omitirán, pues son el mismo cálculo de
antes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#pesos}
\NormalTok{N=}\DecValTok{29}
\NormalTok{n=}\DecValTok{4}
\NormalTok{M_grande=}\KeywordTok{c}\NormalTok{(}\DecValTok{792}\NormalTok{,}\DecValTok{447}\NormalTok{,}\DecValTok{511}\NormalTok{,}\DecValTok{800}\NormalTok{)}
\NormalTok{m_chico=}\KeywordTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{40}\NormalTok{)}
\NormalTok{wij=(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\NormalTok{(M_grande}\OperatorTok{/}\NormalTok{m_chico)}
\NormalTok{wij}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 229.6800 216.0500 185.2375 145.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#p estimado}
\NormalTok{smokers=}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{27}\NormalTok{)}
\NormalTok{y_ij=smokers}\OperatorTok{/}\NormalTok{m_chico}
\NormalTok{y_ij}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.400 0.200 0.300 0.675
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t_est=}\KeywordTok{sum}\NormalTok{(wij}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(y_ij))}
\NormalTok{p_est=t_est}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(M_grande)}
\NormalTok{p_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.479274
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#var p estimado}
\NormalTok{colegio1=}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{10}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{15}\NormalTok{))}
\NormalTok{colegio2=}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{12}\NormalTok{))}
\NormalTok{colegio3=}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{14}\NormalTok{))}
\NormalTok{colegio4=}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{27}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{13}\NormalTok{))}
\NormalTok{var_vector=}\KeywordTok{c}\NormalTok{(}\KeywordTok{var}\NormalTok{(colegio1),}\KeywordTok{var}\NormalTok{(colegio2),}\KeywordTok{var}\NormalTok{(colegio3),}\KeywordTok{var}\NormalTok{(colegio4))}
\NormalTok{var_vector}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2500000 0.1714286 0.2210526 0.2250000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_p_est=}\DecValTok{1}\OperatorTok{/}\KeywordTok{mean}\NormalTok{(M_grande)}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(n}\OperatorTok{/}\NormalTok{N))}\OperatorTok{*}\NormalTok{(}\KeywordTok{var}\NormalTok{(y_ij)}\OperatorTok{/}\NormalTok{n)}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(n}\OperatorTok{*}\NormalTok{N}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(M_grande)}\OperatorTok{^}\DecValTok{2}\NormalTok{))}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(M_grande}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(m_chico}\OperatorTok{/}\NormalTok{M_grande))}\OperatorTok{*}\NormalTok{(var_vector}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\NormalTok{m_chico))}
\NormalTok{var_p_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.958674e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(var_p_est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008341867
\end{verbatim}

Luego, de igual manera hacemos para el total poblacional. La estimación
puntal ya la sacamos para obtener la proporción media.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#t estimado}
\NormalTok{t_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1222.149
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#varianza estimada de t estimado}
\NormalTok{v_est_t_est=N}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{(n}\OperatorTok{/}\NormalTok{N))}\OperatorTok{*}\NormalTok{(}\KeywordTok{var}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{46}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{54}\NormalTok{)))}\OperatorTok{/}\NormalTok{n)}\OperatorTok{+}\NormalTok{(N}\OperatorTok{/}\NormalTok{n)}\OperatorTok{*}\KeywordTok{sum}\NormalTok{((}\DecValTok{1}\OperatorTok{-}\NormalTok{m_chico}\OperatorTok{/}\NormalTok{M_grande)}\OperatorTok{*}\NormalTok{M_grande}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(var_vector}\OperatorTok{/}\NormalTok{m_chico))}
\NormalTok{v_est_t_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 104986.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(v_est_t_est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 324.0166
\end{verbatim}

En la última parte de la pregunta, basta obtener \(R_{a}^2\) mediante su
fórmula. Luego, para diseñar el nuevo muestreo es necesario utilizar:

\[\text{Costo total}= C = c_1 n + c_2 n m\] donde \(c_1\) es el costo
por \(\textbf{UPM}\) (sin incluir es costo de medir las
\(\textbf{USM}\)) y \(c_2\) es el costo de medir cada \(\textbf{USM}\).
Así, \[n_{opt}=\dfrac{C}{c_1+c_2m_{opt}}\] y,
\[m_{opt}=\sqrt{\dfrac{c_1 M (N-1)(1-R_{a}^{2}}{c_2(NM-1)R_{a}^{2}}}\]

En donde \(C\) son las 300 horas, \(c_1\) son las 50 horas y \(c_2\) son
30 minutos. Luego resta encontrar los valores óptimos de \(n\) y \(m\),
aunque en el problema sólo se plantea que se desea un nuevo diseño (sin
ser este el que minimize la varianza), por lo que para un par \((n,m)\)
que satisfaga los anterior, se considera válido.

\subsubsection{Ejercicios Muestreo con probablidad
desiguales}\label{ejercicios-muestreo-con-probablidad-desiguales}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  An investigator wants to take an unequal-probability sample of 10 of
  the 25 psus in the population listed below and in file
  exercise0602.dat, and wishes to sample units with replacement.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{C:/Users/Eloy/Google\%20Drive/EST/Docencia/2020/IEST\%20412\%20-\%20Muestreo\%20II/Ejercicios/Prueba\%201/problema1_2.jpg}
\caption{}
\end{figure}

\begin{itemize}
\tightlist
\item
  Adapt the cumulative-size method to draw a sample of size 10 with
  replacement with probabilities \(\psi_i\). Instead of randomly
  selecting integers between 1 and \(M_0=\sum_{i=1}^{N} M_i\), select 10
  random numbers between 0 and 1.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Primero generamos 10 números aleatorios entre 0 y 1}
\CommentTok{#primero hacemos el ejercicio replicable.}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123098}\NormalTok{)}
\KeywordTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.4535026 0.0875460 0.6916622 0.7765107 0.9507957 0.1972466 0.4302415
##  [8] 0.5193432 0.4748635 0.2287619
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{datos=}\KeywordTok{read.csv}\NormalTok{(}\StringTok{"exercise0602.csv"}\NormalTok{)}
\NormalTok{datos}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    psu      psi
## 1    1 0.000110
## 2    2 0.018556
## 3    3 0.062998
## 4    4 0.078216
## 5    5 0.075245
## 6    6 0.073983
## 7    7 0.076580
## 8    8 0.038981
## 9    9 0.040772
## 10  10 0.022876
## 11  11 0.003721
## 12  12 0.024917
## 13  13 0.040654
## 14  14 0.014804
## 15  15 0.005577
## 16  16 0.070784
## 17  17 0.069635
## 18  18 0.034650
## 19  19 0.069492
## 20  20 0.036590
## 21  21 0.033853
## 22  22 0.016959
## 23  23 0.009066
## 24  24 0.021795
## 25  25 0.059186
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#creamos la frecuencia acumulada}
\NormalTok{v=}\KeywordTok{cumsum}\NormalTok{(datos)}
\NormalTok{v}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    psu      psi
## 1    1 0.000110
## 2    3 0.018666
## 3    6 0.081664
## 4   10 0.159880
## 5   15 0.235125
## 6   21 0.309108
## 7   28 0.385688
## 8   36 0.424669
## 9   45 0.465441
## 10  55 0.488317
## 11  66 0.492038
## 12  78 0.516955
## 13  91 0.557609
## 14 105 0.572413
## 15 120 0.577990
## 16 136 0.648774
## 17 153 0.718409
## 18 171 0.753059
## 19 190 0.822551
## 20 210 0.859141
## 21 231 0.892994
## 22 253 0.909953
## 23 276 0.919019
## 24 300 0.940814
## 25 325 1.000000
\end{verbatim}

Por lo que bajo estos números aleatorios, tenemos que la muestra estará
compuesta por las \(\textbf{UPM}\)

\[\{ 9,21,17,19,25,5,9,13,10,6 \}\]

\begin{itemize}
\tightlist
\item
  Adapt Lahiri's method to draw a sample of size 10 with replacement
  with probabilities \(\psi_i\)
\end{itemize}

Implementamos un pequeño código para que haga el método de lahiri.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123098}\NormalTok{)}
\NormalTok{psi=}\KeywordTok{c}\NormalTok{(datos}\OperatorTok{$}\NormalTok{psi)}
\NormalTok{muestra<-}\KeywordTok{c}\NormalTok{()}
\NormalTok{i=}\DecValTok{1}
\ControlFlowTok{while}\NormalTok{ (i}\OperatorTok{<=}\DecValTok{10}\NormalTok{)\{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{<=}\NormalTok{psi[}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(psi),}\DecValTok{1}\NormalTok{)])\{}
\NormalTok{  muestra=}\KeywordTok{c}\NormalTok{(muestra,}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(psi),}\DecValTok{1}\NormalTok{))}
\NormalTok{  i=i}\OperatorTok{+}\DecValTok{1}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{muestra}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 14 10  7 21 22  4 17 24 17  1
\end{verbatim}

Notamos, que le \(\textbf{UPM}\) 17 se repite dos veces.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Data from the 2000 U.S. Census on population and housing unit counts
  for the counties in Arizona (excluding Maricopa County and Pima
  County, which are much larger than the other counties and would be
  placed in a separate stratum). For this exercise, suppose that year
  2000 population (\(M_i\)) is known and you want to take a sample of
  counties to estimate the total number of housing units
  (\(t=\sum_{i=1}^{13} t_i\)).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{datos=}\KeywordTok{read.csv}\NormalTok{(}\StringTok{"azcounties.csv"}\NormalTok{)}
\NormalTok{datos}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    number       name population housing
## 1       1     Apache      69423   31621
## 2       2    Cochise     117755   51126
## 3       3   Coconino     116320   53443
## 4       4       Gila      51335   28189
## 5       5     Graham      33489   11430
## 6       6   Greenlee       8547    3744
## 7       7     La Paz      19715   15133
## 8       8     Mohave     155032   80062
## 9       9     Navajo      97470   47413
## 10     10      Pinal     179727   81154
## 11     11 Santa Cruz      38381   13036
## 12     12    Yavapai     167517   81730
## 13     13       Yuma     160026   74140
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Calculate the selection probabilities \(\psi_i\) for a sample of size
  1 with probability proportional to 2000 population. Find
  \(\hat{t}_{\psi}\) for each possible sample, and calculate the
  theoretical variance \(\mathbb{V}(\hat{t}_{\psi})\)
\end{itemize}

Primero calculamos las probabilidades de selección, proporcionales a el
número de elementos en cada \(\textbf{UPM}\), así:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob=datos}\OperatorTok{$}\NormalTok{population}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(datos}\OperatorTok{$}\NormalTok{population)}
\NormalTok{prob}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.057150642 0.096938679 0.095757353 0.042260176 0.027568931
##  [6] 0.007036091 0.016229851 0.127625980 0.080239591 0.147955483
## [11] 0.031596140 0.137903925 0.131737158
\end{verbatim}

Luego, nos piden calcular \(\hat{t}_{\psi}\) y su varianza teórica para
cada muestra posible de tamaño 1. Por lo que utilizamos:

\[\widehat{t_{\psi}}=\dfrac{1}{n} \sum_{i\in \mathcal{R}} \dfrac{t_i}{\psi_i}\]

con \(n=1\). Notamos que la sumatoria se simplifica bastante en el caso
de una sola unidad muestral.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#t est}
\NormalTok{t_est=datos}\OperatorTok{$}\NormalTok{housing}\OperatorTok{/}\NormalTok{prob}
\NormalTok{t_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 553292.1 527405.6 558108.6 667034.6 414597.1 532113.6 932417.7
##  [8] 627317.4 590892.8 548502.8 412582.0 592659.0 562787.3
\end{verbatim}

Luego, para la varianza utilizamos:
\[\mathbb{V}[\widehat{t_\psi}]=\dfrac{1}{n}\sum_{i=1}^{N}\psi_i \left( \dfrac{t_i}{\psi_i}-t\right)^2\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#varianza teórica}
\NormalTok{var_teo=(}\DecValTok{1}\OperatorTok{/}\DecValTok{13}\NormalTok{)}\OperatorTok{*}\KeywordTok{sum}\NormalTok{(prob}\OperatorTok{*}\NormalTok{(t_est}\OperatorTok{-}\KeywordTok{sum}\NormalTok{(datos}\OperatorTok{$}\NormalTok{population))}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{var_teo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 32124314799
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(var_teo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 179232.6
\end{verbatim}

\end{document}
